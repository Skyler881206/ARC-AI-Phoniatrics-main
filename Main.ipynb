{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.python.client import device_lib\r\n",
    "print(device_lib.list_local_devices())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import pickle\r\n",
    "from glob import iglob\r\n",
    "import numpy as np\r\n",
    "import librosa\r\n",
    "import soundfile as sf\r\n",
    "\r\n",
    "ORI_PATH = r'C:\\Users\\usaco\\Desktop\\Main_Program\\data_student'\r\n",
    "OUTPUT_DIR = r'C:\\Users\\usaco\\Desktop\\Main_Program\\output'\r\n",
    "\r\n",
    "Ori_SR = 44100\r\n",
    "TARGET_SR = 16000 # sample rate 16000\r\n",
    "AUDIO_LENGTH = 25600\r\n",
    "\r\n",
    "\r\n",
    "class_ids = {\r\n",
    "    'True': 0,\r\n",
    "    'False': 1,\r\n",
    "}\r\n",
    "\r\n",
    "def extract_class_id(pos):\r\n",
    "    if pos==0:\r\n",
    "      return class_ids.get('True')\r\n",
    "    else:\r\n",
    "      return class_ids.get('False')\r\n",
    "\r\n",
    "def read_audio_from_filename(filename, target_sr, ori_sr):\r\n",
    "    audio, _ = librosa.load(filename, sr=ori_sr, mono=True)\r\n",
    "    audio_target_sr = librosa.resample(y=audio, orig_sr=_, target_sr=target_sr) # ori_sr to target_sr\r\n",
    "    audio_target_sr = audio_target_sr.reshape(-1, 1)\r\n",
    "    #print(audio.shape)\r\n",
    "    #print(audio_target_sr.shape)\r\n",
    "    return audio_target_sr\r\n",
    "\r\n",
    "def convert_data():\r\n",
    "    i = j = k = 0\r\n",
    "    for root, dirs, files in os.walk(os.path.abspath(ORI_PATH)):\r\n",
    "      for file in files:\r\n",
    "        if (\"wav\" in file):\r\n",
    "          pos = file.find(\"16_\")\r\n",
    "\r\n",
    "          if(pos == 0):\r\n",
    "            j = j + 1\r\n",
    "          else:\r\n",
    "            k = k + 1\r\n",
    "\r\n",
    "          class_id = extract_class_id(pos)\r\n",
    "          path = os.path.join(root, file)\r\n",
    "          audio_buf = read_audio_from_filename(path, target_sr=TARGET_SR, ori_sr=Ori_SR)\r\n",
    "          # normalize mean 0, variance 1\r\n",
    "          audio_buf = (audio_buf - np.mean(audio_buf)) / np.std(audio_buf)\r\n",
    "          original_length = len(audio_buf)\r\n",
    "          #print(file, original_length, np.round(np.mean(audio_buf), 4), np.std(audio_buf))\r\n",
    "\r\n",
    "          if (original_length < AUDIO_LENGTH):\r\n",
    "            audio_buf = np.concatenate((audio_buf, np.zeros(shape=(AUDIO_LENGTH - original_length, 1))))\r\n",
    "            print('PAD New length =', len(audio_buf))\r\n",
    "          elif (original_length > AUDIO_LENGTH):\r\n",
    "            audio_buf = audio_buf[0:AUDIO_LENGTH]\r\n",
    "            print('CUT New length =', len(audio_buf))\r\n",
    "\r\n",
    "          output_filename = os.path.join(OUTPUT_DIR, str(i) + '.pkl')\r\n",
    "\r\n",
    "          out = {'class_id': class_id,\r\n",
    "               'audio': audio_buf,\r\n",
    "               'sr': TARGET_SR}\r\n",
    "\r\n",
    "          with open(output_filename, 'wb+') as w:\r\n",
    "            pickle.dump(out, w)\r\n",
    "          i = i + 1\r\n",
    "          print('Data:', i, ',Right:', j, 'False', k)\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    convert_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\r\n",
    "import pickle\r\n",
    "from keras.utils.np_utils import to_categorical\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "ORI_PATH = r'C:\\Users\\usaco\\Desktop\\Main_Program\\data_student'\r\n",
    "OUTPUT_DIR = r'C:\\Users\\usaco\\Desktop\\Main_Program\\output'\r\n",
    "\r\n",
    "def get_data(file_list):\r\n",
    "    def load_into(_filename, _x, _y):\r\n",
    "        with open(_filename, 'rb') as f:\r\n",
    "            audio_element = pickle.load(f)\r\n",
    "            _x.append(audio_element['audio'])\r\n",
    "            _y.append(int(audio_element['class_id']))\r\n",
    "    \r\n",
    "    x,y = [], []\r\n",
    "    for filename in file_list:\r\n",
    "      load_into(filename, x, y)\r\n",
    "    return np.array(x), np.array(y)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "\r\n",
    "  num_classes = 2  \r\n",
    "  train_files = glob(os.path.join(OUTPUT_DIR, '**.pkl'))\r\n",
    "  x, y = get_data(train_files)\r\n",
    "  y = to_categorical(y, num_classes=num_classes)\r\n",
    "\r\n",
    "  print(x)\r\n",
    "  print(y)\r\n",
    " \r\n",
    " \r\n",
    "#   test_files = glob(os.path.join(OUTPUT_DIR_TEST, '**.pkl'))\r\n",
    "#   x_te, y_te = get_data(test_files)\r\n",
    "#   y_te = to_categorical(y_te, num_classes=num_classes)\r\n",
    "\r\n",
    "\r\n",
    "  print('x.shape =', x.shape)\r\n",
    "  print('y.shape =', y.shape)\r\n",
    "  #print('x_te.shape =', x_te.shape)\r\n",
    "  #print('y_te.shape =', y_te.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Train Test Split\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(y_test.shape)\r\n",
    "\r\n",
    "X_train =  np.expand_dims(X_train, axis=3)\r\n",
    "X_test =  np.expand_dims(X_test, axis=3)\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.callbacks import ModelCheckpoint\r\n",
    "from keras.callbacks import ReduceLROnPlateau\r\n",
    "import keras.backend as K\r\n",
    "from keras import regularizers\r\n",
    "from keras.layers import Lambda\r\n",
    "# from keras.layers.convolutional import Conv1D, MaxPooling1D\r\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
    "from keras.layers.core import Activation, Dense, Flatten\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.models import Sequential\r\n",
    "import numpy as np\r\n",
    "from glob import glob\r\n",
    "import tensorflow as tf\r\n",
    "import datetime\r\n",
    "\r\n",
    "AUDIO_LENGTH = 25600\r\n",
    "SAVE_DIR = r'C:\\Users\\usaco\\Desktop\\Main_Program'\r\n",
    "\r\n",
    "def m5(num_classes=5):\r\n",
    "    print('Using Model M5')\r\n",
    "    m = Sequential()\r\n",
    "    m.add(Conv2D(64,\r\n",
    "                 input_shape=(AUDIO_LENGTH, 1, 1),\r\n",
    "                 kernel_size=(80,1),\r\n",
    "                 strides=(4,1),\r\n",
    "                 padding='same',\r\n",
    "                 kernel_initializer='glorot_uniform',\r\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\r\n",
    "    # m.add(BatchNormalization())\r\n",
    "    # m.add(Activation('relu'))\r\n",
    "    # m.add(MaxPooling2D(pool_size=(4,1), strides=None))\r\n",
    "    # m.add(Conv2D(128,\r\n",
    "    #              kernel_size=(3,1),\r\n",
    "    #              strides=(1,1),\r\n",
    "    #              padding='same',\r\n",
    "    #              kernel_initializer='glorot_uniform',\r\n",
    "    #              kernel_regularizer=regularizers.l2(l=0.0001)))\r\n",
    "    m.add(BatchNormalization())\r\n",
    "    m.add(Activation('relu'))\r\n",
    "    m.add(MaxPooling2D(pool_size=(4,1), strides=None))\r\n",
    "    m.add(Conv2D(256,\r\n",
    "                 kernel_size=(3,1),\r\n",
    "                 strides=(1,1),\r\n",
    "                 padding='same',\r\n",
    "                 kernel_initializer='glorot_uniform',\r\n",
    "                 kernel_regularizer=regularizers.l2(l=0.0001)))\r\n",
    "    # m.add(BatchNormalization())\r\n",
    "    # m.add(Activation('relu'))\r\n",
    "    # m.add(MaxPooling1D(pool_size=4, strides=None))\r\n",
    "    # m.add(Conv1D(512,\r\n",
    "    #              kernel_size=3,\r\n",
    "    #              strides=1,\r\n",
    "    #              padding='same',\r\n",
    "    #              kernel_initializer='glorot_uniform',\r\n",
    "                #  kernel_regularizer=regularizers.l2(l=0.0001)))\r\n",
    "    m.add(BatchNormalization())\r\n",
    "    m.add(Activation('relu'))\r\n",
    "    m.add(MaxPooling2D(pool_size=(4,1), strides=None))\r\n",
    "    # m.add(Lambda(lambda x: K.mean(x, axis=1)))  # Same as GAP for 1D Conv Layer\r\n",
    "    m.add(Flatten())\r\n",
    "    m.add(Dense(num_classes, activation='softmax'))\r\n",
    "    return m\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    num_classes = 2\r\n",
    "    model = m5(num_classes=num_classes)\r\n",
    "\r\n",
    "    if model is None:\r\n",
    "        exit('Something went wrong!!')\r\n",
    "\r\n",
    "    model.compile(optimizer='adam',\r\n",
    "                  loss='categorical_crossentropy',\r\n",
    "                  metrics=['accuracy'])\r\n",
    "    print(model.summary())\r\n",
    "\r\n",
    "\r\n",
    "    # if the accuracy does not increase over 10 epochs, reduce the learning rate by half.\r\n",
    "    \r\n",
    "    batch_size = 128\r\n",
    "\r\n",
    "    log_dir = os.path.join(SAVE_DIR, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n",
    "\r\n",
    "    checkpoint = ModelCheckpoint(os.path.join(SAVE_DIR, 'model_check3_2D.h5'), monitor='val_accuracy',verbose=1,save_best_only=True)\r\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\r\n",
    "\r\n",
    "    model.fit(x=X_train,\r\n",
    "              y=y_train,\r\n",
    "              batch_size=batch_size,\r\n",
    "              epochs=200,\r\n",
    "              verbose=1,\r\n",
    "              shuffle=True,\r\n",
    "              validation_data=(X_test, y_test),\r\n",
    "              callbacks=[checkpoint, reduce_lr,tensorboard_callback])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%tensorboard -- logs/gradient_tape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "import itertools\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "import numpy as np\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "def plot_confusion_matrix(cm, classes,\r\n",
    "                          normalize=False,\r\n",
    "                          title='Confusion matrix',\r\n",
    "                          cmap=plt.cm.Blues):\r\n",
    "    \"\"\"\r\n",
    "    This function prints and plots the confusion matrix.\r\n",
    "    Normalization can be applied by setting `normalize=True`.\r\n",
    "    \"\"\"\r\n",
    "    if normalize:\r\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
    "        print(\"Normalized confusion matrix\")\r\n",
    "    else:\r\n",
    "        print('Confusion matrix, without normalization')\r\n",
    "\r\n",
    "    print(cm)\r\n",
    "\r\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
    "    plt.title(title)\r\n",
    "    plt.colorbar()\r\n",
    "    tick_marks = np.arange(len(classes))\r\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "    plt.yticks(tick_marks, classes)\r\n",
    "\r\n",
    "    fmt = '.2f' if normalize else 'd'\r\n",
    "    thresh = cm.max() / 2.\r\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
    "                 horizontalalignment=\"center\",\r\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
    "\r\n",
    "    plt.ylabel('True label')\r\n",
    "    plt.xlabel('Predicted label')\r\n",
    "    plt.tight_layout()\r\n",
    "\r\n",
    "def convert_to_labels(one_hot_encoding):\r\n",
    "    Labels = []\r\n",
    "    for i in range(5527):\r\n",
    "        if one_hot_encoding[i][0] > 0.5:\r\n",
    "            Labels.append(1)\r\n",
    "        else:\r\n",
    "            Labels.append(0)\r\n",
    "    \r\n",
    "    return Labels\r\n",
    "\r\n",
    "\r\n",
    "m = keras.models.load_model(r'C:\\Users\\usaco\\Desktop\\Main_Program\\model_check3_2D.h5')\r\n",
    "y_predict = m.predict(X_test, batch_size=None, verbose=1, steps=None)\r\n",
    "\r\n",
    "y_pred = convert_to_labels(y_predict)\r\n",
    "#print(y_pred)\r\n",
    "y_true = convert_to_labels(y_test)\r\n",
    "#print(y_true)\r\n",
    "target_names = ['Right', 'False']\r\n",
    "month = 2\r\n",
    "\r\n",
    "print (\"month = \" + str(month))\r\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\r\n",
    "print (\"**************************************************************\")\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\r\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names,normalize=True,\r\n",
    "                    title=\"month = \" + str(month) + ' confusion matrix')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'Convert to TFLite'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow.compat.v2 as tf\r\n",
    "from tensorflow import keras\r\n",
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import logging\r\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\r\n",
    "    \r\n",
    "print(tf.__version__)\r\n",
    "assert tf.__version__ >= '2.3'\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model=keras.models.load_model(r'C:\\Users\\usaco\\Desktop\\Main_Program\\model_check3_2D.h5')\r\n",
    "\r\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "tflite_model = converter.convert()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
    "\r\n",
    "tflite_model_quant = converter.convert()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(X_train.dtype)\r\n",
    "X_train = X_train.astype(np.float32)\r\n",
    "print(X_train.dtype)\r\n",
    "\r\n",
    "print(X_test.dtype)\r\n",
    "X_test = X_test.astype(np.float32)\r\n",
    "print(X_test.dtype)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def representative_data_gen():\r\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\r\n",
    "    # Model has only one input so each data point has one element.\r\n",
    "    yield [input_value]\r\n",
    "\r\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
    "converter.representative_dataset = representative_data_gen\r\n",
    "\r\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\r\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\r\n",
    "\r\n",
    "# Set the input and output tensors to INT16 (APIs added in r2.3)\r\n",
    "converter.inference_input_type = tf.int16\r\n",
    "converter.inference_output_type = tf.int16\r\n",
    "tflite_model_quant = converter.convert()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\r\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\r\n",
    "print('input: ', input_type)\r\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\r\n",
    "print('output: ', output_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "tflite_models_dir = pathlib.Path(r\"C:\\Users\\usaco\\Desktop\\Main_Program\")\r\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\r\n",
    "\r\n",
    "# Save the unquantized/float model:\r\n",
    "tflite_model_file = tflite_models_dir/\"model3_2D.tflite\"\r\n",
    "tflite_model_file.write_bytes(tflite_model)\r\n",
    "# Save the quantized model:\r\n",
    "tflite_model_quant_file = tflite_models_dir/\"model3_2D_quant.tflite\"\r\n",
    "tflite_model_quant_file.write_bytes(tflite_model_quant)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
